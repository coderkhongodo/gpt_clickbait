# GPT-OSS 20B + QLoRA â€“ Vietnamese Sentiment (UIT-VSFC)

End-to-end pipeline to fine-tune `openai/gpt-oss-20b` on UIT-VSFC for 3-class sentiment (0=negative, 1=neutral, 2=positive), with weighted loss, constrained decoding, and full evaluation.

## ðŸš€ Quick Start

### 1) CÃ i Ä‘áº·t

```bash
pip install -r requirements.txt
```

YÃªu cáº§u pháº§n cá»©ng/pháº§n má»m:
- Python 3.10+
- GPU: A6000 Ada 48GB (Ä‘Ã£ kiá»ƒm thá»­ tá»‘t). CÃ¡c GPU VRAM â‰¥ 24GB cÅ©ng cÃ³ thá»ƒ cháº¡y khi báº­t QLoRA + grad accumulation.
- CUDA: 12.8 (PyTorch 2.2+ há»— trá»£ CUDA 12.x). CÃ i Ä‘áº·t theo hÆ°á»›ng dáº«n PyTorch chÃ­nh thá»©c tÆ°Æ¡ng á»©ng há»‡ Ä‘iá»u hÃ nh.

Gá»£i Ã½ cÃ i PyTorch phÃ¹ há»£p CUDA 12.x (Windows/Linux, pip):

```bash
# CUDA 12.x build (khuyÃªn dÃ¹ng):
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio

# Náº¿u dÃ¹ng CPU-only (khÃ´ng khuyáº¿n nghá»‹ Ä‘á»ƒ train):
# pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio
```

LÆ°u Ã½:
- CUDA há»‡ thá»‘ng 12.8 tÆ°Æ¡ng thÃ­ch vá»›i build cu121 cá»§a PyTorch.
- bitsandbytes>=0.43.0 há»— trá»£ CUDA 12.x; trÃªn Windows cáº§n báº£n Python 3.10+.

### 2) Chuáº©n bá»‹ dá»¯ liá»‡u (UIT-VSFC)

Äáº·t dá»¯ liá»‡u gá»‘c á»Ÿ:

```
data/uit-vsfc/
  train/{sents.txt, sentiments.txt, topics.txt}
  dev/{sents.txt, sentiments.txt, topics.txt}
  test/{sents.txt, sentiments.txt, topics.txt}
```

Sinh instruction 3 lá»›p (kÃ¨m â€œÄÃ¡p Ã¡n:â€):

```bash
python src/processing/prepare_vsfc_sentiment.py
```

Äáº§u ra:

```
data_processed/jsonl_text_vsfc_sentiment/
  train_instruction.jsonl
  val_instruction.jsonl
  test_instruction.jsonl
```

## ðŸ› ï¸ Huáº¥n luyá»‡n (QLoRA)

Script: `src/train/train_qlora_gpt_oss_20b.py` (argparse Ä‘áº§y Ä‘á»§).

VÃ­ dá»¥ train chuáº©n 3 lá»›p vá»›i class-weights (neutral=5):

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_sentiment \
  --output_dir models/gpt-oss-20b-qlora-sent-3cls \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 16 \
  --lr 5e-4 --epochs 3 --log_steps 10 \
  --optim paged_adamw_8bit --report_to none \
  --warmup_ratio 0.1 --save_total_limit 3 \
  --lora_r 32 --lora_alpha 64 --lora_dropout 0.1 \
  --class_weights "1.0,5.0,1.0"
```

Cháº¿ Ä‘á»™ thá»­ nhanh (subset + epochs nhá»):

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_sentiment \
  --output_dir models/gpt-oss-20b-qlora-sent-3cls-test \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 4 \
  --lr 5e-4 --epochs 1 --test_mode
```

Notes cáº¥u hÃ¬nh trÃªn A6000 Ada 48GB + CUDA 12.8:
- Máº·c Ä‘á»‹nh script tá»± phÃ¡t hiá»‡n pre-quant (MXFP4). Náº¿u base model khÃ´ng cÃ³ pre-quant, sáº½ fallback 4-bit (bitsandbytes) Ä‘á»ƒ vá»«a VRAM.
- Khuyáº¿n nghá»‹: `--batch_size 1 --grad_accum 16..32`, `--bf16` báº­t sáºµn; cÃ³ thá»ƒ tÄƒng `--epochs` tuá»³ thá»i gian.
- Weighted loss Ã¡p táº¡i token nhÃ£n cuá»‘i cÃ¹ng (mapping nhÃ£n '0','1','2').

### Class weights + sampling (Ä‘á» xuáº¥t cho sentiment â€“ neutral ~4.3%)

Hai ká»¹ thuáº­t bá»• trá»£ nhau (khÃ´ng trÃ¹ng láº·p):

- Class weights: pháº¡t lá»—i cá»§a lá»›p neutral máº¡nh hÆ¡n â†’ gradient cáº£i thiá»‡n má»—i láº§n neutral xuáº¥t hiá»‡n.
- Oversampling/weighted sampling: tÄƒng táº§n suáº¥t neutral trong batch â†’ mÃ´ hÃ¬nh â€œtháº¥y biÃªnâ€ Ä‘á»§ Ä‘á»ƒ há»c. Vá»›i `batch_size=1`, náº¿u khÃ´ng tÄƒng táº§n suáº¥t, cÃ³ thá»ƒ pháº£i cháº¡y hÃ ng chá»¥c bÆ°á»›c má»›i gáº·p neutral â†’ weights khÃ³ phÃ¡t huy.

Khuyáº¿n nghá»‹ thá»±c dá»¥ng (train-only, giá»¯ nguyÃªn dev/test):

- Má»¥c tiÃªu â€œtáº§n suáº¥t neutralâ€ ~15â€“20% bÆ°á»›c train.
- Class weights khá»Ÿi Ä‘iá»ƒm: `neg=1.0, neutral=5.0, pos=1.0` (thá»­ grid 3/5/7 cho neutral).
- Sampling weights (xÃ¡c suáº¥t láº¥y máº«u theo lá»›p) hÆ°á»›ng tá»›i tá»‰ lá»‡ ~ `neg:neu:pos = 0.4:0.2:0.4`.

VÃ­ dá»¥ dÃ¹ng `WeightedRandomSampler` (minh hoáº¡):

```python
from torch.utils.data import DataLoader, WeightedRandomSampler
import numpy as np

# y: list/array nhÃ£n 0/1/2 theo thá»© tá»± máº«u trong táº­p train
cls_counts = np.bincount(y, minlength=3)  # [cnt_neg, cnt_neu, cnt_pos]
target_ratio = np.array([0.40, 0.20, 0.40])

curr_ratio = cls_counts / cls_counts.sum()
scale = target_ratio / (curr_ratio + 1e-9)
class_weights_for_sampling = scale / scale.sum()

sample_weights = np.array([class_weights_for_sampling[label] for label in y], dtype=np.float64)
sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)

loader = DataLoader(train_dataset, batch_size=1, sampler=sampler)
```

Ghi chÃº:
- Khi dÃ¹ng TRL SFTTrainer, Ä‘á»ƒ Ã¡p sampler tuá»³ biáº¿n cáº§n bá»c dataset hoáº·c tá»± táº¡o `Trainer`/`DataLoader` ngoÃ i. Náº¿u muá»‘n, báº¡n cÃ³ thá»ƒ má»Ÿ PR Ä‘á»ƒ tÃ­ch há»£p cá» `--weighted_sampler` vÃ o pipeline.

TÃ­ch há»£p sáºµn trong script train (Ä‘Ã£ há»— trá»£ cá»):

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_sentiment \
  --output_dir models/gpt-oss-20b-qlora-sent-3cls-balanced \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 16 \
  --lr 5e-4 --epochs 3 \
  --class_weights "1.0,5.0,1.0" \
  --weighted_sampler --target_sampling_ratio "0.40,0.20,0.40"
```

## ðŸ”Ž Suy luáº­n (constrained decoding tuá»³ chá»n)

Script: `src/interface/inference_gpt_oss_20b.py`

```bash
python src/interface/inference_gpt_oss_20b.py --constrained --allowed_labels 012
```

Tuá»³ chá»n:
- `--allowed_labels`: chuá»—i nhÃ£n cho phÃ©p (vd: `012` cho 3 lá»›p).
- `--num_samples`: sá»‘ lÆ°á»£ng máº«u hiá»ƒn thá»‹ tá»« file test nhá» (náº¿u dÃ¹ng `jsonl_text_small/test.jsonl`).

## ðŸ“ˆ ÄÃ¡nh giÃ¡ trÃªn táº­p test

Script: `src/eval/evaluate_model.py`

```bash
python src/eval/evaluate_model.py \
  --model_id openai/gpt-oss-20b \
  --adapter_dir models/gpt-oss-20b-qlora-sent-3cls/best \
  --test_file data_processed/jsonl_text_vsfc_sentiment/test_instruction.jsonl \
  --allowed_labels 012 \
  --max_samples 0 \
  --output_csv eval_results_vsfc.csv \
  --summary_json eval_summary_vsfc.json \
  --report_txt classification_report_vsfc.txt \
  --cm_csv confusion_matrix_vsfc.csv
```

In ra vÃ  lÆ°u:
- Accuracy, Precision/Recall/F1 (macro)
- Classification report (txt)
- Confusion matrix (CSV)
- Káº¿t quáº£ chi tiáº¿t tá»«ng máº«u (CSV) vÃ  summary (JSON)

## ðŸ§© BÃ i toÃ¡n Topic (UIT-VSFC â€“ 4 lá»›p)

### 1) Chuáº©n bá»‹ dá»¯ liá»‡u topic

```bash
python src/processing/prepare_vsfc_topic.py
```

Äáº§u ra:

```
data_processed/jsonl_text_vsfc_topic/
  train_instruction.jsonl
  val_instruction.jsonl
  test_instruction.jsonl
```

### 2) Huáº¥n luyá»‡n topic (QLoRA)

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_topic \
  --output_dir models/gpt-oss-20b-qlora-topic-4cls \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 16 \
  --lr 5e-4 --epochs 3 --log_steps 10 \
  --optim paged_adamw_8bit --report_to none \
  --warmup_ratio 0.1 --save_total_limit 3 \
  --lora_r 32 --lora_alpha 64 --lora_dropout 0.1
```

Cháº¿ Ä‘á»™ thá»­ nhanh:

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_topic \
  --output_dir models/gpt-oss-20b-qlora-topic-4cls-test \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 4 \
  --lr 5e-4 --epochs 1 --test_mode
```

### 3) Suy luáº­n topic (rÃ ng buá»™c 0/1/2/3)

```bash
python src/interface/inference_gpt_oss_20b.py --constrained --allowed_labels 0123
```

### 4) ÄÃ¡nh giÃ¡ topic

Sá»­ dá»¥ng evaluator chung (há»— trá»£ `--allowed_labels 0123`):

```bash
python src/eval/evaluate_model.py \
  --model_id openai/gpt-oss-20b \
  --adapter_dir models/gpt-oss-20b-qlora-topic-4cls/best \
  --test_file data_processed/jsonl_text_vsfc_topic/test_instruction.jsonl \
  --allowed_labels 0123 \
  --output_csv eval_results_topic.csv \
  --summary_json eval_summary_topic.json \
  --report_txt classification_report_topic.txt \
  --cm_csv confusion_matrix_topic.csv
```

### 5) Gá»£i Ã½ class weights cho topic (máº¥t cÃ¢n báº±ng)

Theo phÃ¢n bá»‘ vÃ­ dá»¥ (0:11607, 1:3040, 2:712, 3:816), cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i:

- Khuyáº¿n nghá»‹ (sqrt-inverse, á»•n Ä‘á»‹nh): `--class_weights "1.0,2.0,4.1,3.8"`
- Máº¡nh hÆ¡n (inverse freq, cÃ³ giá»›i háº¡n): `--class_weights "1.0,3.5,6.0,5.5"`

Tip: báº¯t Ä‘áº§u vá»›i bá»™ sqrt-inverse; náº¿u lá»›p hiáº¿m (2,3) cÃ²n yáº¿u, tÄƒng dáº§n trá»ng sá»‘ 2â†’4.5 vÃ  3â†’4.2. LuÃ´n báº­t constrained decoding khi suy luáº­n: `--constrained --allowed_labels 0123`.

## ðŸ“Š PhÃ¢n tÃ­ch dá»¯ liá»‡u

Script EDA: `src/analysis/sentiment_eda_vsfc.py`

```bash
python src/analysis/sentiment_eda_vsfc.py --vsfc_dir data/uit-vsfc --save_plots --save_preview
```

Sinh biá»ƒu Ä‘á»“ phÃ¢n bá»‘ nhÃ£n, Ä‘á»™ dÃ i; preview JSONL 3 lá»›p.

## ðŸ§­ Cáº¥u trÃºc dá»± Ã¡n (rÃºt gá»n)

```
data/uit-vsfc/...
data_processed/jsonl_text_vsfc_sentiment/{train,val,test}_instruction.jsonl
models/gpt-oss-20b-qlora-*/best/
src/
  analysis/sentiment_eda_vsfc.py
  eval/evaluate_model.py
  interface/inference_gpt_oss_20b.py
  processing/prepare_vsfc_sentiment.py
  train/train_qlora_gpt_oss_20b.py
```

## ðŸ“‹ Requirements

```
torch>=2.1.0
transformers>=4.42.0
peft>=0.11.1
trl>=0.9.4
datasets>=2.20.0
accelerate>=0.31.0
bitsandbytes>=0.43.0
scikit-learn>=1.3.0
pandas>=2.0.0
```