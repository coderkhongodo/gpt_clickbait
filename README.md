# GPT-OSS 20B + QLoRA â€“ Vietnamese Clickbait Detection

End-to-end pipeline tinh chá»‰nh `openai/gpt-oss-20b` cho phÃ¢n loáº¡i clickbait tiáº¿ng Viá»‡t:
- PhÃ¢n loáº¡i Clickbait (2 lá»›p: 0=khÃ´ng pháº£i clickbait, 1=clickbait)
- Sá»­ dá»¥ng dataset clickbait tiáº¿ng Viá»‡t vá»›i 3,414 máº«u
- Káº¿t há»£p tiÃªu Ä‘á» vÃ  ná»™i dung bÃ i bÃ¡o Ä‘á»ƒ phÃ¢n loáº¡i

Dataset bao gá»“m:
- 2,349 máº«u khÃ´ng pháº£i clickbait (68.8%)
- 1,065 máº«u clickbait (31.2%)
- Nguá»“n: CÃ¡c trang bÃ¡o tiáº¿ng Viá»‡t (VnExpress, Tuá»•i Tráº», SaoStar, v.v.)

## ðŸš€ Quick Start

### 1) CÃ i Ä‘áº·t

```bash
pip install -r requirements.txt
```

YÃªu cáº§u pháº§n cá»©ng/pháº§n má»m:
- Python 3.10+
- GPU: A6000 Ada 48GB (Ä‘Ã£ kiá»ƒm thá»­ tá»‘t). CÃ¡c GPU VRAM â‰¥ 24GB cÅ©ng cÃ³ thá»ƒ cháº¡y khi báº­t QLoRA + grad accumulation.
- CUDA: 12.8 (PyTorch 2.2+ há»— trá»£ CUDA 12.x). CÃ i Ä‘áº·t theo hÆ°á»›ng dáº«n PyTorch chÃ­nh thá»©c tÆ°Æ¡ng á»©ng há»‡ Ä‘iá»u hÃ nh.

Gá»£i Ã½ cÃ i PyTorch phÃ¹ há»£p CUDA 12.x (Windows/Linux, pip):

```bash
# CUDA 12.x build (khuyÃªn dÃ¹ng):
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio

# Náº¿u dÃ¹ng CPU-only (khÃ´ng khuyáº¿n nghá»‹ Ä‘á»ƒ train):
# pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio
```

LÆ°u Ã½:
- CUDA há»‡ thá»‘ng 12.8 tÆ°Æ¡ng thÃ­ch vá»›i build cu121 cá»§a PyTorch.
- bitsandbytes>=0.43.0 há»— trá»£ CUDA 12.x; trÃªn Windows cáº§n báº£n Python 3.10+.

### 2) Chuáº©n bá»‹ dá»¯ liá»‡u (Clickbait Dataset)

Äáº·t dá»¯ liá»‡u gá»‘c á»Ÿ:

```
data/data_raw/
  clickbait_dataset_vietnamese.csv
  clickbait_dataset_vietnamese.jsonl
```

Sinh instruction 3 lá»›p (kÃ¨m â€œÄÃ¡p Ã¡n:â€):

Chá»n má»™t trong hai (hoáº·c cáº£ hai):

- Sentiment 2 lá»›p (khuyáº¿n nghá»‹):
```bash
python src/processing/prepare_vsfc_sentiment_2cls.py
```
Äáº§u ra: `data_processed/jsonl_text_vsfc_sentiment_2cls/{train,val,test}_instruction.jsonl`

- Topic 4 lá»›p:
```bash
python src/processing/prepare_vsfc_topic.py
```
Äáº§u ra: `data_processed/jsonl_text_vsfc_topic/{train,val,test}_instruction.jsonl`

## ðŸ› ï¸ Huáº¥n luyá»‡n (QLoRA)

Script: `src/train/train_qlora_gpt_oss_20b.py` (argparse Ä‘áº§y Ä‘á»§).

### Sentiment 2 lá»›p (0=neg, 1=pos)
```bash
python3 src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_sentiment_2cls \
  --output_dir models/gpt-oss-20b-qlora-sent-2cls \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 16 \
  --lr 5e-4 --epochs 10  --log_steps 10 \
  --optim paged_adamw_8bit --report_to none \
  --warmup_ratio 0.1 --save_total_limit 3 \
  --lora_r 32 --lora_alpha 64 --lora_dropout 0.1
```

Cháº¿ Ä‘á»™ thá»­ nhanh (subset + epochs nhá»):

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_sentiment \
  --output_dir models/gpt-oss-20b-qlora-sent-3cls-test \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 4 \
  --lr 5e-4 --epochs 1 --test_mode
```

Notes cáº¥u hÃ¬nh trÃªn A6000 Ada 48GB + CUDA 12.8:
- Máº·c Ä‘á»‹nh script tá»± phÃ¡t hiá»‡n pre-quant (MXFP4). Náº¿u base model khÃ´ng cÃ³ pre-quant, sáº½ fallback 4-bit (bitsandbytes) Ä‘á»ƒ vá»«a VRAM.
- Khuyáº¿n nghá»‹: `--batch_size 1 --grad_accum 16..32`, `--bf16` báº­t sáºµn; cÃ³ thá»ƒ tÄƒng `--epochs` tuá»³ thá»i gian.
- Weighted loss Ã¡p táº¡i token nhÃ£n cuá»‘i cÃ¹ng (mapping nhÃ£n '0','1','2').

Ghi chÃº: Vá»›i 2 lá»›p Ä‘Ã£ loáº¡i bá» neutral, khÃ´ng cáº§n sampler/class-weight Ä‘áº·c biá»‡t.

## ðŸ”Ž Suy luáº­n (constrained decoding)

Script: `src/interface/inference_gpt_oss_20b.py`

```bash
# Sentiment 2 lá»›p
python src/interface/inference_gpt_oss_20b.py --constrained --allowed_labels 01

# Topic 4 lá»›p
python src/interface/inference_gpt_oss_20b.py --constrained --allowed_labels 0123
```

Tuá»³ chá»n:
- `--allowed_labels`: chuá»—i nhÃ£n cho phÃ©p (vd: `012` cho 3 lá»›p).
- `--num_samples`: sá»‘ lÆ°á»£ng máº«u hiá»ƒn thá»‹ tá»« file test nhá» (náº¿u dÃ¹ng `jsonl_text_small/test.jsonl`).

## ðŸ“ˆ ÄÃ¡nh giÃ¡ trÃªn táº­p test (lÆ°u vÃ o results/)

Script: `src/eval/evaluate_model.py`

```bash
# Sentiment 2 lá»›p
mkdir -p results && python src/eval/evaluate_model.py \
  --model_id openai/gpt-oss-20b \
  --adapter_dir models/gpt-oss-20b-qlora-sent-2cls/best \
  --test_file data_processed/jsonl_text_vsfc_sentiment_2cls/test_instruction.jsonl \
  --allowed_labels 01 \
  --output_csv results/eval_results_sent2cls_test.csv \
  --summary_json results/eval_summary_sent2cls_test.json \
  --report_txt results/classification_report_sent2cls_test.txt \
  --cm_csv results/confusion_matrix_sent2cls_test.csv
```

In ra vÃ  lÆ°u:
- Accuracy, Precision/Recall/F1 (macro)
- Classification report (txt)
- Confusion matrix (CSV)
- Káº¿t quáº£ chi tiáº¿t tá»«ng máº«u (CSV) vÃ  summary (JSON)

## ðŸ§© BÃ i toÃ¡n Topic (UIT-VSFC â€“ 4 lá»›p)

### 1) Chuáº©n bá»‹ dá»¯ liá»‡u topic

```bash
python src/processing/prepare_vsfc_topic.py
```

Äáº§u ra:

```
data_processed/jsonl_text_vsfc_topic/
  train_instruction.jsonl
  val_instruction.jsonl
  test_instruction.jsonl
```

### 2) Huáº¥n luyá»‡n topic (QLoRA)

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_topic \
  --output_dir models/gpt-oss-20b-qlora-topic-4cls \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 16 \
  --lr 5e-4 --epochs 3 --log_steps 10 \
  --optim paged_adamw_8bit --report_to none \
  --warmup_ratio 0.1 --save_total_limit 3 \
  --lora_r 32 --lora_alpha 64 --lora_dropout 0.1
```

Cháº¿ Ä‘á»™ thá»­ nhanh:

```bash
python src/train/train_qlora_gpt_oss_20b.py \
  --model_id openai/gpt-oss-20b \
  --data_dir data_processed/jsonl_text_vsfc_topic \
  --output_dir models/gpt-oss-20b-qlora-topic-4cls-test \
  --train_file train_instruction.jsonl \
  --val_file val_instruction.jsonl \
  --batch_size 1 --eval_batch_size 1 --grad_accum 4 \
  --lr 5e-4 --epochs 1 --test_mode
```

### 3) Suy luáº­n topic (rÃ ng buá»™c 0/1/2/3)

```bash
python src/interface/inference_gpt_oss_20b.py --constrained --allowed_labels 0123
```

### 4) ÄÃ¡nh giÃ¡ topic (lÆ°u vÃ o results/)

Sá»­ dá»¥ng evaluator chung (há»— trá»£ `--allowed_labels 0123`):

```bash
mkdir -p results && python src/eval/evaluate_model.py \
  --model_id openai/gpt-oss-20b \
  --adapter_dir models/gpt-oss-20b-qlora-topic-4cls/best \
  --test_file data_processed/jsonl_text_vsfc_topic/test_instruction.jsonl \
  --allowed_labels 0123 \
  --output_csv results/eval_results_topic_test.csv \
  --summary_json results/eval_summary_topic_test.json \
  --report_txt results/classification_report_topic_test.txt \
  --cm_csv results/confusion_matrix_topic_test.csv
```

### 5) Gá»£i Ã½ class weights cho topic (máº¥t cÃ¢n báº±ng)

Theo phÃ¢n bá»‘ vÃ­ dá»¥ (0:11607, 1:3040, 2:712, 3:816), cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i:

- Khuyáº¿n nghá»‹ (sqrt-inverse, á»•n Ä‘á»‹nh): `--class_weights "1.0,2.0,4.1,3.8"`
- Máº¡nh hÆ¡n (inverse freq, cÃ³ giá»›i háº¡n): `--class_weights "1.0,3.5,6.0,5.5"`

Tip: báº¯t Ä‘áº§u vá»›i bá»™ sqrt-inverse; náº¿u lá»›p hiáº¿m (2,3) cÃ²n yáº¿u, tÄƒng dáº§n trá»ng sá»‘ 2â†’4.5 vÃ  3â†’4.2. LuÃ´n báº­t constrained decoding khi suy luáº­n: `--constrained --allowed_labels 0123`.

## ðŸ“Š PhÃ¢n tÃ­ch dá»¯ liá»‡u

Script EDA: `src/analysis/sentiment_eda_vsfc.py`

```bash
python src/analysis/sentiment_eda_vsfc.py --vsfc_dir data/uit-vsfc --save_plots --save_preview
```

Sinh biá»ƒu Ä‘á»“ phÃ¢n bá»‘ nhÃ£n, Ä‘á»™ dÃ i; preview JSONL 3 lá»›p.

## ðŸ§­ Cáº¥u trÃºc dá»± Ã¡n (rÃºt gá»n)

```
data/uit-vsfc/...
data_processed/
  jsonl_text_vsfc_sentiment_2cls/{train,val,test}_instruction.jsonl
  jsonl_text_vsfc_topic/{train,val,test}_instruction.jsonl
models/gpt-oss-20b-qlora-*/best/
src/
  analysis/sentiment_eda_vsfc.py
  eval/evaluate_model.py
  interface/inference_gpt_oss_20b.py
  processing/prepare_vsfc_sentiment_2cls.py
  processing/prepare_vsfc_topic.py
  train/train_qlora_gpt_oss_20b.py
docs/
  sentiment_classification_report.md
  topic_classification_report.md
```

## ðŸ“‹ Requirements

```
torch>=2.1.0
transformers>=4.42.0
peft>=0.11.1
trl>=0.9.4
datasets>=2.20.0
accelerate>=0.31.0
bitsandbytes>=0.43.0
scikit-learn>=1.3.0
pandas>=2.0.0
```